<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Events | FunAI  research Lab</title>
    <meta name="author" content="FunAI  research Lab" />
    <meta name="description" content="Fundamental AI research Lab
" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/funai-50x50.ico"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/events/">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="//"><span class="font-weight-bold">FunAI </span>research Lab</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">FunAI Lab</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/jobs/">Jobs</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/contact/">Contact</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Events</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <p>Subscribe to our mailing list <a href="https://lists.lrz.de/mailman/listinfo/lmu-cis-mainlp-events" target="_blank" rel="noopener noreferrer">here</a>.
<!-- pages/events.md -->
<!-- events are sorted by filename (reverse order) --></p>
<div class="events">
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2024-05-13-shubhra-kanti-karmaker"><a href="#2024-05-13-shubhra-kanti-karmaker">Democratizing AI through Controlled Narrative Generation and Knowledge Grounding</a></h2>


  <div>
<h3>Speaker:</h3> Shubhra Kanti Karmaker<br> Assistant Professor, Auburn University (Alabama, U.S.)</div>


<div>
<h3>Date:</h3> June 17, 2024; 09:00–10:00
<br>
  <h3>Location:</h3>
  
    <a href="https://mainlp.github.io/contact/" target="_blank" rel="noopener noreferrer"> Akademiestr. 7, room 218A (meeting room)</a>
  

</div>


  <div>
<h3>Abstract:</h3> Even though Artificial Intelligence (AI) has existed for a long time, its broad accessibility is a recent development, thanks to Generative AI models like ChatGPT for its human-like interactions. While such broad accessibility provides a great opportunity to democratize AI across general people, it comes with several key risks and challenges, including but not limited to a lack of Knowledge Grounding/Contextual Understanding in unseen/new domains, an abundance of Biased Contents/Narratives, and a lack of Utility-Centric Evaluation of Generative AI systems. This talk will focus on two specific challenges related to the democratization of AI, i.e., 1) Controlled Narrative Generation and 2) Knowledge Grounding in Conversational-AI systems, and discuss practical solutions and appropriate evaluation approaches for them. The talk will also introduce several utility-centric evaluation metrics for measuring the quality of Generative and Conversational AI systems that correlate with human judgments better than traditional metrics. Finally, the talk will highlight some interesting future directions in line with the democratization of AI and its associated challenges. </div>


<div>

  
  <img src="../assets/img/shubhra.jpg" alt="Portrait of Shubhra Kanti Karmaker" class="event-pic event-pic-right">


  <h3>Bio:</h3> 'Dr. Shubhra Kanti Karmaker (``Santu') (Co-PI) is an Assistant Professor in the Department of Computer Science and Software Engineering at Auburn University, Alabama. With a broad interest in the academic field of Artificial Intelligence and Data Science, his primary research focus lies at the intersection of Natural Language Processing (NLP) and Information Retrieval (IR). More specifically, his research is primarily driven by the following broad research question: “How can we make AI/Data Science more accessible and useful to the end users in order to democratize AI to a broader audience?” '


  <a href="https://karmake2.github.io/" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2024-06-7-elena-lloret"><a href="#2024-06-7-elena-lloret">Current NLG research at GPLSI group</a></h2>


  <div>
<h3>Speaker:</h3> Elena Lloret Pastor, <br>professor, Universitat d'Alacant</div>


<div>
<h3>Date:</h3> June 7, 2024; 13:15–14:15
<br>
  <h3>Location:</h3>
  
    <a href="https://mainlp.github.io/contact/" target="_blank" rel="noopener noreferrer"> Akademiestr. 7, room 218A (meeting room)</a>
  

</div>


  <div>
<h3>Abstract:</h3> The main aim of this talk is to look for potential synergies between MaiNLP and GPLSI research groups. Therefore, in this talk, I will present the research carried out in the GPLSI Research Group of the University of Alicante (Spain) concerning Natural Language Generation (NLG). I will first provide a brief introductory information about my background and my research group. Then, I will introduce two relevant current projects that deals with NLG as their main topic: 1) CORTEX - Concious Text Generation, and 2) ILENIA project, describing the most recent research that has been developed within them, together with work in progress and future steps. Finally, I will outline some possible activities to do during my visit.</div>


<div>

  
  <img src="../assets/img/elloret.png" alt="Portrait of Elena Lloret Pastor" class="event-pic event-pic-right">


  <h3>Bio:</h3> PhD in Computer Applications, June 2011. Currently, Elena is a member of the Natural Language Processing research group at the University of Alicante. Her research interests focus on Natural Language Processing, and in particular on Text Summarization, Natural Language Generation, and Text Simplification.


  <a href="https://www.dlsi.ua.es/~elloret/" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2024-05-13-matthias-orlikowski"><a href="#2024-05-13-matthias-orlikowski">Annotators Aren't Asocial Atoms: Modeling Individual Perspectives and Social Groups</a></h2>


  <div>
<h3>Speaker:</h3> Matthias Orlikowski<br> PhD candidate, Bielefeld University (Germany)</div>


<div>
<h3>Date:</h3> May 13, 2024; 16:00–17:00
<br>
  <h3>Location:</h3>
  
    <a href="https://mainlp.github.io/contact/" target="_blank" rel="noopener noreferrer"> Akademiestr. 7, room 218A (meeting room)</a>
  

</div>


  <div>
<h3>Abstract:</h3> Annotators, like we all, are shaped to some extent by their membership in social groups. Some groups are formed based on socially-relevant categories, like age or gender, others can be more local and temporary. For example, the group of all annotators in the annotation process is just that, a group. If groups have an impact on us, can we include them in our models to better capture variation in annotation? I will present results from two recent works to provide some tentative answers to this question. In one case we find that groups based on sociodemographics might be too coarse to be informative [1]. In the other we see that it is beneficial to model the annotators of a dataset as a group and in relation to one another [2].<br>[1]<a href="https://aclanthology.org/2023.acl-short.88/" target="_blank" rel="noopener noreferrer"> https://aclanthology.org/2023.acl-short.88/</a><br>[2]<a href="https://aclanthology.org/2023.emnlp-main.687/" target="_blank" rel="noopener noreferrer"> https://aclanthology.org/2023.emnlp-main.687/</a> </div>


<div>

  
  <img src="../assets/img/matthias-orlikowski.jpg" alt="Portrait of Matthias Orlikowski" class="event-pic event-pic-right">


  <h3>Bio:</h3> Matthias Orlikowski is a PhD student in the <a href="https://www.uni-bielefeld.de/fakultaeten/technische-fakultaet/arbeitsgruppen/semantic-computing/team/matthias-orlikowski/" target="_blank" rel="noopener noreferrer">Semantic Computing Group</a> at Bielefeld University (Germany) supervised by Philipp Cimiano. He works on systems to analyse online discussions with a particular focus on subjectivity and human label variation. In 2022 and 2023 he visited Dirk Hovy's <a href="https://milanlproc.github.io/" target="_blank" rel="noopener noreferrer">MilaNLP Lab</a> at Bocconi University (Italy) to work on related problems in modeling sociodemographics and continues to collaborate with the group.


  <a href="https://orlikow.ski/" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2024-05-06-russa-biwas"><a href="#2024-05-06-russa-biwas">Bridging Knowledge Gaps: Harnessing Embedding Techniques for Knowledge Graph Completion</a></h2>


  <div>
<h3>Speaker:</h3> Russa Biwas<br> Postdoc, Hasso-Plattner Institute, Potsdam (Germany)</div>


<div>
<h3>Date:</h3> May 6, 2024; 13:00–14:00
<br>
  <h3>Location:</h3>
  
    <a href="https://mainlp.github.io/contact/" target="_blank" rel="noopener noreferrer"> Akademiestr. 7, room 218A (meeting room)</a>
  

</div>


  <div>
<h3>Abstract:</h3> Knowledge Graphs (KGs) are the most widely used representation of structured information about a particular domain consisting of billions of facts in the form of entities (nodes), and relations (edges) between them and encapsulate the semantic type information of the entities. Open KGs such as DBpedia, Wikidata, and YAGO, are multilingual and are heuristically created, automatically generated or human-curated. Over the past two decades, KGs have grown in various domains such as government, scholarly data, and biomedical fields and have been used in Machine Learning applications namely entity linking, question answering, and recommender systems. However, these KGs are often incomplete i.e., there are missing links between entities. The talk begins by elucidating the significance of KG completion in enhancing comprehensiveness. It highlights the role of ML algorithms in leveraging the existing structure and semantics encoded within KGs to predict and infer missing links, thereby enriching the knowledge representation. However, existing research has focused mostly on monolingual KGs, leaving multilingual KGs unexplored. This talk also discusses the open challenges and research gaps in multilingual KG completion.</div>


<div>

  
  <img src="../assets/img/russabiswas.jpg" alt="Portrait of Russa Biwas" class="event-pic event-pic-right">


  <h3>Bio:</h3> Russa Biswas is a postdoctoral researcher at Hasso Plattner Institute, Potsdam, working on the intersection of Knowledge Graphs and Large Language Models. She earned her PhD from Karlsruhe Institute of Technology, AIFB, Germany and was also part of the Information Service Engineering group at FIZ Karlsruhe. Prior to that, she worked as a research associate at DFKI, Saarbrücken, and at the Computational Linguistics group at Saarland University and as a research assistant at Fraunhofer IZFP, Saarbrücken. She did her masters in Computer Science from Saarland University. Her research focuses on multilingual KGs, factuality in LLMs, and ML in Graphs.


  <a href="https://scholar.google.de/citations?user=kSHWjuoAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2024-04-08-hyewon-jang"><a href="#2024-04-08-hyewon-jang">Towards well-rounded sarcasm handling by language models</a></h2>


  <div>
<h3>Speaker:</h3> Hyewon Jang<br> PhD candidate, University of Konstanz (Germany)</div>


<div>
<h3>Date:</h3> April 8, 2024; 9:00–10:00
<br>
  <h3>Location:</h3>
  
    <a href="https://mainlp.github.io/contact/" target="_blank" rel="noopener noreferrer"> Akademiestr. 7, room 218A (meeting room)</a>
  

</div>


  <div>
<h3>Abstract:</h3> We investigate the ways of reaching well-rounded handling of sarcasm by language models (LMs), exemplified by the ability to generalize well, to understand the reasoning behind the use of sarcasm, or to generate sarcasm at an appropriate time. As the first attempt, we tested the robustness of sarcasm detection models by examining their behavior when fine-tuned on four sarcasm datasets containing varying characteristics of sarcasm: label source (authors vs. third-party), domain (social media/online vs. offline conversations/dialogues), style (aggressive vs. humorous mocking). We found that most LMs failed to generalize well to the other datasets, implying that one type of dataset cannot represent all sorts of sarcasm with different styles and domains. Compared to the existing datasets, LMs fine-tuned on the new dataset we newly released showed the highest generalizability to other datasets. From analyzing these results, we show that sarcasm encompasses a broad spectrum of characteristics, intricately intertwined with factors requiring inference and pragmatics, and argue that future research of sarcasm should take these factors into account. We conclude by discussing future work in this direction.</div>


<div>

  
  <img src="../assets/img/hyewon.jpg" alt="Portrait of Hyewon Jang" class="event-pic event-pic-right">


  <h3>Bio:</h3> Hyewon Jang is a PhD candidate in computational psycholinguistics at the <a href="https://www.ling.uni-konstanz.de/" target="_blank" rel="noopener noreferrer">University of Konstanz</a> supervised by <a href="https://www.ling.uni-konstanz.de/frassinelli/" target="_blank" rel="noopener noreferrer">Diego Frassinelli</a> and <a href="https://www.ling.uni-konstanz.de/braun-zinn/prof-dr-bettina-braun/" target="_blank" rel="noopener noreferrer">Bettina Braun</a>. Hyewon uses experimental and computational linguistics methods to investigate the pragmatic dimensions of language that make human language complex and fun, with sarcasm being the current topic of interest.


  <a href="https://hyewon-jang-kn.github.io/" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2024-01-24-rob-van-der-goot"><a href="#2024-01-24-rob-van-der-goot">ROBustness in NLP over the years</a></h2>


  <div>
<h3>Speaker:</h3> Rob van der Goot<br> Assistant Professor at the IT University of Copenhagen</div>


<div>
<h3>Date:</h3> January 24, 2024; 11:00–12:00
<br>
  <h3>Location:</h3>
  
    <a href="https://mainlp.github.io/contact/" target="_blank" rel="noopener noreferrer"> Akademiestr. 7, room 218A (meeting room)</a>
  

</div>


  <div>
<h3>Abstract:</h3> This talk will consist of three parts 1. Lexical normalization of social media data and its downstream effect on syntactic tasks. 2. Multi-task learning for adaptation in challenging setups. 3. What are open challenges for fundamental NLP tasks like language identification and word segmentation?</div>


<div>

  
  <img src="../assets/img/rob.jpg" alt="Portrait of Rob van der Goot" class="event-pic event-pic-left">


  <h3>Bio:</h3> Rob van der Goot's main interest is in low-resource setups in natural language processing, which could be in a variety of dimensions, including language(-variety), domain, or task. He did his PhD on the use of normalization for syntactic parsing of social media data, one specific case of a challenging transfer setup. Afterwards, he focused on using multi-task learning in challenging settings. Most recently, Rob focuses on more low-level tasks (language identification, tokenization) in challenging settings (cross-lingual, cross-domain, for low-resource languages/scripts).


  <a href="https://robvanderg.github.io/" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2023-12-19-martijn-bartelds"><a href="#2023-12-19-martijn-bartelds">Representing Low-Resource Language Varieties: Improved Methods for Spoken Language Processing</a></h2>


  <div>
<h3>Speaker:</h3> Martijn Bartelds<br> Incoming PostDoc at Stanford University</div>


<div>
<h3>Date:</h3> December 19, 2023; 14:00–15:00
<br>
  <h3>Location:</h3>
  
    <a href="https://mainlp.github.io/contact/" target="_blank" rel="noopener noreferrer"> Akademiestr. 7, room 218A (meeting room)</a>
  

</div>


  <div>
<h3>Abstract:</h3> Languages are often treated as homogeneous entities, while they are typically composed of multiple varieties. Most language varieties do not correspond to administrative boundaries, such as provinces or states within nations, and they often form a continuum with neighboring varieties. Studying language variation can provide valuable insights into how language varieties relate to their linguistic communities. To this end, it is important to focus on spoken language, as many languages do not have a standard written system.<br><br>In this talk, I will introduce our new method to describe and model language variation, which leverages speech representations from self-supervised neural network models to quantify differences between the pronunciations of speakers from different language varieties. This new method assesses the differences between language varieties more accurately and efficiently compared to previously-used methods. Additionally, I will talk about the use of these neural network models to develop speech technology systems that can help empower low-resource language varieties. In particular, I will present our audio-based search algorithm to automatically identify occurrences of a spoken search term in a large collection of spoken materials, improving access to resources that would normally require manual annotation. Furthermore, I will discuss an approach to improve speech recognition performance for several language varieties from different language families. This technology can be a promising step towards the important goal of developing speech technology that is inclusive of the world’s languages.</div>


<div>

  
  <img src="../assets/img/martijn-bartelds.jpg" alt="Portrait of Martijn Bartelds" class="event-pic event-pic-left">


  <h3>Bio:</h3> Martijn is an incoming Postdoctoral Scholar in Computer Science at Stanford University, working with Professor Dan Jurafsky. His research focuses on developing and applying natural language processing methods to describe and model resource-scarce languages. He is particularly interested in speech processing with extremely low-resource languages, dialects, and non-native speech. Martijn was awarded his PhD at the University of Groningen (cum laude), where he was advised by Professor Martijn Wieling and Professor Mark Liberman.


  <a href="https://martijnbartelds.nl/" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2023-11-20-jan-philip-whale"><a href="#2023-11-20-jan-philip-whale">We are Who We Cite: Bridges of Influence Between Natural Language Processing and Other Academic Fields</a></h2>


  <div>
<h3>Speaker:</h3> Jan Philip Whale<sup>1</sup>, <a href="#2023-05-08-saif-mohammad">Saif M. Mohammad<sup>2</sup></a> <br> <sup>1</sup>PhD candidate, University of Göttingen <br> <sup>2</sup>Senior Research Scientist, National Research Council Canada</div>


<div>
<h3>Date:</h3> November 20, 2023; 09:00–10:00
<br>
  <h3>Location:</h3>
  
    <a href="https://www.hispanistentag2017.romanistik.uni-muenchen.de/bilder/planta-baja.png" target="_blank" rel="noopener noreferrer"> Raum A 017 Geschw.-Scholl-Pl. 1</a>
  

</div>


  <div>
<h3>Abstract:</h3> Natural Language Processing (NLP) is poised to substantially influence the world. However, significant progress comes hand-in-hand with substantial risks. Addressing them requires broad engagement with various fields of study. Yet, little empirical work examines the state of such engagement (past or current). In this paper, we quantify the degree of influence between 23 fields of study and NLP (on each other). We analyzed ~77k NLP papers, ~3.1m citations from NLP papers to other papers, and ~1.8m citations from other papers to NLP papers. We show that, unlike most fields, the cross-field engagement of NLP, measured by our proposed Citation Field Diversity Index (CFDI), has declined from 0.58 in 1980 to 0.31 in 2022 (an all-time low). In addition, we find that NLP has grown more insular -- citing increasingly more NLP papers and having fewer papers that act as bridges between fields. NLP citations are dominated by computer science; Less than 8% of NLP citations are to linguistics, and less than 3% are to math and psychology. These findings underscore NLP's urgent need to reflect on its engagement with various fields.</div>


<div>

  
  <img src="../assets/img/jan.jpeg" alt="Portrait of Jan Philip" class="event-pic event-pic-right">


  <h3>Bio:</h3> Jan Philip Wahle is a PhD candidate in computer science at the University of Göttingen in Germany. His primary research revolves around paraphrasing, plagiarism detection, and responsible NLP, as well as their various applications such as summarization or misinformation detection. The work presented during this talk was performed during a research visit at the National Research Council Canada. Now, Jan is a visiting researcher at the University of Toronto. Updates about his research can be followed on his website, X, and LinkedIn. → <a href="https://jpwahle.com/" target="_blank" rel="noopener noreferrer">Website</a>  | <a href="https://twitter.com/jpwahle" target="_blank" rel="noopener noreferrer">X</a> | <a href="https://www.linkedin.com/in/jan-philip-wahle/" target="_blank" rel="noopener noreferrer">LinkedIn</a>


</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2023-11-08-paul-röttger"><a href="#2023-11-08-paul-ro%CC%88ttger">LLM Safety: What does it mean and how do we get there?</a></h2>


  <div>
<h3>Speaker:</h3> Paul Röttger<br> PostDoc in MilaNLP Lab at Bocconi University</div>


<div>
<h3>Date:</h3> November 8, 2023; 11:00–12:00
<br>
  <h3>Location:</h3>
  
    <a href="https://mainlp.github.io/contact/" target="_blank" rel="noopener noreferrer"> Akademiestr. 7, room 218A (meeting room)</a>
  

</div>


  <div>
<h3>Abstract:</h3> AI safety, and specifically the safety of large language models (LLMs) like ChatGPT, is receiving unprecedented public and regulatory attention. In my talk, split into two parts, I will try to give some more concrete meaning to this often nebulous topic and the challenges it poses. First, I will define LLM safety with a focus on near-term risks and explain why LLM safety matters, countering common arguments against this line of work. I will also give an overview of current methods for ensuring LLM safety, from red-teaming to fine-grained feedback learning. Second, I will zoom in on imitation learning, where models are trained on outputs from other models, as a particularly common way of improving the capabilities of open LLMs. I will talk about our own work in progress on safety by imitation, where we extend imitation learning to safety-related behaviours. I will present the resources we have built already, and then transition into an open discussion about our hypotheses and planned experiments, followed by a Q&amp;A to close out the hour.</div>


<div>

  
  <img src="../assets/img/paul-rottger.jpeg" alt="Portrait of Paul Röttger" class="event-pic event-pic-left">


  <h3>Bio:</h3> Paul is a postdoctoral researcher in Dirk Hovy‘s MilaNLP Lab at Bocconi University. His work is located at the intersection of computation, language and society. Right now, he is particularly interested in evaluating and aligning social values in large generative language models, and, by extension, in AI safety. Before coming to Milan, he completed his PhD at the University of Oxford, where he worked on improving the evaluation and effectiveness of large language models for hate speech detection.


  <a href="https://paulrottger.com/" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2023-09-25-janet-liu"><a href="#2023-09-25-janet-liu">The Pivotal Role of Genres: Insights from English RST Parsing and Abstractive Summarization </a></h2>


  <div>
<h3>Speaker:</h3> Janet Liu<br> PhD candidate, Georgetown University</div>


<div>
<h3>Date:</h3> September 25, 2023; 10:30–11:30
<br>
  <h3>Location:</h3>
  
    <a href="https://mainlp.github.io/contact/" target="_blank" rel="noopener noreferrer"> Akademiestr. 7, room 218A (meeting room)</a>
  

</div>


  <div>
<h3>Abstract:</h3> Text exhibits significant variations across types such as news articles, academic papers, social media posts, vlogs, and more. Recognizing the importance of genre and using data from diverse genres in training can enable NLP models to generalize and perform effectively across diverse textual contexts. While previous work has studied the role of genre in tasks and linguistic phenomena such as dependency parsing (Müller-Eberstein et al., EMNLP 2021; Müller-Eberstein et al., TLT-SyntaxFest 2021), NLI (Nangia et al., RepEval 2017), and lexical semantics (Kober et al., COLING 2020), in this talk I will present our work that emphasizes the importance of genre diversity in the case of RST parsing and summarization.<br>I will first discuss our results from the English RST parsing task that a heterogeneous training regime is critical for stable and generalizable RST models, regardless of parser architectures [1,3].  Then, I will present GUMSum [2], a carefully crafted dataset of English summaries in 12 written and spoken genres for evaluation of abstractive summarization. This work emphasizes the complexities of producing high-quality summaries across genres, where impressive models like GPT-3 fall short of human performance, highlighting the need to consider genre-specific guidelines for crafting accurate and faithful summaries. Together, we hope our findings and resources can not only raise awareness and help level the playing field across text-types, demographics, and domains in English but also offer insights that can benefit the same or analogous tasks and phenomena in other languages.<br>[1] <a href="https://aclanthology.org/2023.eacl-main.227/" target="_blank" rel="noopener noreferrer">https://aclanthology.org/2023.eacl-main.227/</a><br>[2] <a href="https://aclanthology.org/2023.findings-acl.593/" target="_blank" rel="noopener noreferrer">https://aclanthology.org/2023.findings-acl.593/</a><br>[3] <a href="https://aclanthology.org/2023.law-1.17/" target="_blank" rel="noopener noreferrer">https://aclanthology.org/2023.law-1.17/</a>
</div>


<div>

  
  <img src="../assets/img/janet.png" alt="Portrait of Janet Liu" class="event-pic event-pic-right">


  <h3>Bio:</h3> Yang Janet Liu (she/her/hers, go by Janet) is a PhD Candidate in Computational Linguistics in the Department of Linguistics at Georgetown University where she is advised by Amir Zeldes, PhD and works on computational and corpus-based approaches to discourse-level linguistic phenomena (e.g., discourse relations and relation signaling) and their applications such as summarization. Specifically, her research focuses on the generalizability of discourse understanding and parsing in Rhetorical Structure Theory (RST). She co-organized the <a href="https://sites.google.com/georgetown.edu/disrpt2021" target="_blank" rel="noopener noreferrer">2021</a> and <a href="https://sites.google.com/view/disrpt2023/" target="_blank" rel="noopener noreferrer">2023</a> DISRPT Shared Task on Discourse Segmentation, Connective and Relation Identification across Formalisms. She has been a reviewer for the main *ACL venues (ACL, EACL, NAACL, AACL), SIGDIAL, as well as the Dialogue and Discourse journal etc., and is an Area Chair of the Discourse and Pragmatics track at EMNLP 2023. Previously, she did internships at Spotify (2021, 2023) and Alexa AI at Amazon (2020).


  <a href="https://janetlauyeung.github.io/" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2023-07-14-lea-frermann"><a href="#2023-07-14-lea-frermann">Conflicts, Villains, Resolutions: Towards models of Narrative Media Framing</a></h2>


  <div>
<h3>Speaker:</h3> Dr. Lea Frermann<br> Lecturer, The University of Melbourne</div>


<div>
<h3>Date:</h3> July 14, 2023; 09:00–10:00
<br>
  <h3>Location:</h3>
  
    <a href="https://www.lmu.de/raumfinder/#/building/bw0147/map?room=014701112_" target="_blank" rel="noopener noreferrer"> Amalienstr. 73A - 112</a>
  

</div>


  <div>
<h3>Abstract:</h3> Stories have existed as long as human societies, and are fundamental to communication, culture, and cognition. This talk looks at the interaction of narratives and media framing, i.e., the deliberate presentation of information to elicit a desired response or shift in the reader’s attitude. While rich theories of media framing have emerged from the political and communication sciences, NLP approaches to automatic frame prediction tend to oversimplify the concept. In particular, current approaches focus on overly localized lexical signals, make unwarranted independence assumptions, and ignore the broader, narrative context of news articles. This talk presents our recent work which incorporates narrative themes,  roles of involved actors, and the interaction multiple frames in a news article as a step towards a computational framework of narrative framing. Quantitative evaluation and case studies on media framing of climate change reflect a benefit of the more nuanced emerging frame representations.</div>


<div>

  
  <img src="../assets/img/lea.jpg" alt="Portrait of Lea Frermann" class="event-pic event-pic-left">


  <h3>Bio:</h3> Lea Frermann is a lecturer (assistant professor) and DECRA fellow at the University of Melbourne. Her research combines natural language processing with the cognitive and social sciences to understand how humans learn about and represent complex information and to enable models to do the same in fair and robust ways. Recent projects include models of meaning change; of common sense knowledge in humans and language representations; and automatic story understanding in both fiction (books or movies) and the real world (as narratives in news reporting on complex issues like climate change).


  <a href="http://www.frermann.de/" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2023-06-05-yves-scherrer"><a href="#2023-06-05-yves-scherrer">Corpus-based computational dialectology – Data, methods and results</a></h2>


  <div>
<h3>Speaker:</h3> Dr. Yves Scherrer<br> University lecturer, University of Helsinki</div>


<div>
<h3>Date:</h3> June 05, 2023; 17:00–18:00
<br>
  <h3>Location:</h3>
  
    Akademiestr. 7, room 218A (meeting room)
  

</div>


  <div>
<h3>Abstract:</h3> The CorCoDial (corpus-based computational dialectology) project aims to infer dialect classifications from variation-rich corpora, focusing in particular on the dialect-to-standard normalization task to introduce comparability between different texts. I will start by presenting a multilingual collection of phonetically transcribed and orthographically normalized corpora. This collection forms the data basis of four case studies. In the first study, we investigate to what extent topic models can find dialectological rather than semantic topics. In the second experiment, we evaluate character alignment methods from different research traditions on a range of desirable and undesirable characteristics. The third case study introduces dialect-to-standard normalization as a distinct sequence-to-sequence task and compares various normalization methods used in previous work. In the last study, we focus on neural normalization and investigate what the embeddings of speaker labels can tell us about the origin of the speakers.</div>


<div>

  
  <img src="../assets/img/yves.png" alt="Portrait of Yves Scherrer" class="event-pic event-pic-right">


  <h3>Bio:</h3> Yves Scherrer is a University Lecturer in Language Technology at the University of Helsinki and, from August 2023 onwards, an Associate Professor in NLP at the University of Oslo. He defended his PhD thesis on the computational modelling of Swiss German dialects, with an emphasis on machine translation techniques, in 2012 at the University of Geneva. In 2021, he obtained the title of Docent in Language Technology from the University of Helsinki.<br>Yves Scherrer has been involved in a wide range of projects in the areas of language technology, dialectology, and corpus linguistics. His current research focuses on the annotation and analysis of dialect corpora as well as on tasks and methods related to machine translation. This research is embedded in the <i>CorCoDial – Corpus-based computational dialectology</i> research project, funded by the Academy of Finland (2021–2025).


  <a href="https://blogs.helsinki.fi/yvesscherrer/" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2023-05-15-michael-hedderich"><a href="#2023-05-15-michael-hedderich">Making Building NLP Models More Accessible</a></h2>


  <div>
<h3>Speaker:</h3> Dr. Michael A. Hedderich<br> Postdoctoral researcher, Cornell University</div>


<div>
<h3>Date:</h3> May 15, 2023; 17:00–18:00
<br>
  <h3>Location:</h3>
  
    Akademiestr. 7, room 218A (meeting room)
  

</div>


  <div>
<h3>Abstract:</h3> AI and NLP are entering more and more disciplines and applications. Individuals, research groups, and organizations who are interested in AI are limited in what they can do, however, due to reasons such as lack of labeled data, complexity of the model-building process, missing AI literacy, and applications that do not apply to their use cases. In this talk, I'll present two projects that aim at lowering the entry barriers to model development. The first part will cover a study on using low-resource techniques for under-resourced African languages. I'll discuss the lessons we learned when evaluating in a realistic environment and the importance of integrating the human factor in this evaluation. In the second part of the talk, I'll present Premise, a tool that explains where an NLP classifier fails. Based on the minimum description length principle, it provides a set of robust and global explanations of a model's behavior. For VQA and NER, we identify the issues different blackbox classifiers have and we also show how these insights can be used to improve models.</div>


<div>

  
  <img src="../assets/img/michael-talk.png" alt="Portrait of Michael A. Hedderich" class="event-pic event-pic-left">


  <h3>Bio:</h3> Michael A. Hedderich is a postdoctoral researcher at Cornell University, working with Qian Yang at the intersection of NLP and AI with HCI. Having a background in both NLP and ML as well as HCI methodology, he is interested in developing new foundational technology as well as building bridges from AI to other interested fields. His collaborations span a wide range of disciplines including archaeology, education, interaction design, participatory design, and biomedicine. Before joining Cornell, Michael obtained his PhD in ML and NLP at Saarland University, Germany, with Dietrich Klakow and was then part of Antti Oulasvirta's HCI group at Aalto University, Finland. Past research affiliations also include Rutgers University, Disney Research Studios, and Amazon.


  <a href="https://www.michael-hedderich.de" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
<div class="event">
	  <!-- _includes/events.html -->

<h2 class="event-title" id="2023-05-08-saif-mohammad"><a href="#2023-05-08-saif-mohammad">The Search for Emotions, Creativity, and Fairness in Language</a></h2>


  <div>
<h3>Speaker:</h3> Dr. Saif M. Mohammad (he, him, his)<br> Senior Research Scientist, National Research Council Canada</div>


<div>
<h3>Date:</h3> May 8, 2023; 9:00–10:00
<br>
  <h3>Location:</h3>
  
    <a href="https://www.lmu.de/raumfinder/#/building/bw0000/map?room=000000116_" target="_blank" rel="noopener noreferrer"> LMU main building (Geschwister-Scholl-Platz 1), room A 015</a>
  

</div>


  <div>
<h3>Abstract:</h3> Emotions are central to human experience, creativity, and behavior. They are crucial for organizing meaning and reasoning about the world we live in. They are ubiquitous and everyday, yet complex and nuanced. In this talk, I will describe our work on the search for emotions in language — by humans (through data annotation projects) and by machines (in automatic emotion and sentiment analysis systems). I will outline ways in which emotions can be represented, challenges in obtaining reliable annotations, and approaches that lead to high-quality annotations and useful sentiment analysis systems. I will discuss wide-ranging applications of emotion detection in natural language processing, psychology, social sciences, digital humanities, and computational creativity. Along the way, I will discuss various ethical considerations involved in emotion recognition and sentiment analysis — the often unsaid assumptions and the real-world implications of our choices.</div>


<div>

  
  <img src="../assets/img/saif.png" alt="Portrait of Saif Mohammad" class="event-pic event-pic-right">


  <h3>Bio:</h3> Dr. Saif M. Mohammad is a Senior Research Scientist at the National Research Council Canada (NRC). He received his Ph.D. in Computer Science from the University of Toronto. Before joining NRC, he was a Research Associate at the Institute of Advanced Computer Studies at the University of Maryland, College Park. His research interests are in Natural Language Processing (NLP), especially Lexical Semantics, Emotions and Language, Computational Creativity, AI Ethics, NLP for psychology, and Computational Social Science. He is currently an associate editor for Computational Linguistics, JAIR,  and TACL, and Senior Area Chair for ACL Rolling Review. His word--emotion resources, such as the NRC Emotion Lexicon and VAD Lexicon, are widely used for analyzing emotions in text. His work has garnered media attention, including articles in Time, SlashDot, LiveScience, io9, The Physics arXiv Blog, PC World, and Popular Science.


  <a href="http://saifmohammad.com" target="_blank" rel="noopener noreferrer"> → Website</a>

</div>

    </div>
</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container">
        © Copyright 2024 FunAI  research Lab. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. <a href="https://fontawesome.com/" target="_blank" rel="noopener noreferrer">Font Awesome</a> icons <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer">CC-BY 4.0</a>.
<a href="http://localhost:4000//contact">Impressum</a>.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
